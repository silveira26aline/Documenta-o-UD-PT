{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import estrutura_ud\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = estrutura_ud.Corpus(recursivo=True)\n",
    "corpus.load('bosque.conllu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locuções verbais aspectuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570\n",
      "31\n",
      "acabar de & 11\\\\\\hline\n",
      "acabar por & 30\\\\\\hline\n",
      "andar a & 3\\\\\\hline\n",
      "chegar a & 22\\\\\\hline\n",
      "começar a & 58\\\\\\hline\n",
      "começar por & 6\\\\\\hline\n",
      "continuar a & 57\\\\\\hline\n",
      "continuar por & 1\\\\\\hline\n",
      "deixar de & 30\\\\\\hline\n",
      "dever a & 1\\\\\\hline\n",
      "estar a & 124\\\\\\hline\n",
      "estar para & 1\\\\\\hline\n",
      "estar por & 1\\\\\\hline\n",
      "ficar a & 4\\\\\\hline\n",
      "ficar de & 1\\\\\\hline\n",
      "haver a & 1\\\\\\hline\n",
      "haver de & 2\\\\\\hline\n",
      "haver que & 1\\\\\\hline\n",
      "ir a & 3\\\\\\hline\n",
      "ir de & 1\\\\\\hline\n",
      "parar de & 3\\\\\\hline\n",
      "passar a & 43\\\\\\hline\n",
      "poder a & 3\\\\\\hline\n",
      "ser de & 3\\\\\\hline\n",
      "tender a & 1\\\\\\hline\n",
      "ter a & 9\\\\\\hline\n",
      "ter de & 62\\\\\\hline\n",
      "ter que & 3\\\\\\hline\n",
      "tornar a & 1\\\\\\hline\n",
      "vir a & 42\\\\\\hline\n",
      "voltar a & 42\\\\\\hline\n",
      "\n",
      "estar a & 124\\\\\\hline\n",
      "ter de & 62\\\\\\hline\n",
      "começar a & 58\\\\\\hline\n",
      "continuar a & 57\\\\\\hline\n",
      "passar a & 43\\\\\\hline\n",
      "vir a & 42\\\\\\hline\n",
      "voltar a & 42\\\\\\hline\n",
      "acabar por & 30\\\\\\hline\n",
      "deixar de & 30\\\\\\hline\n",
      "chegar a & 22\\\\\\hline\n",
      "acabar de & 11\\\\\\hline\n",
      "ter a & 9\\\\\\hline\n",
      "começar por & 6\\\\\\hline\n",
      "ficar a & 4\\\\\\hline\n",
      "andar a & 3\\\\\\hline\n",
      "ir a & 3\\\\\\hline\n",
      "parar de & 3\\\\\\hline\n",
      "poder a & 3\\\\\\hline\n",
      "ser de & 3\\\\\\hline\n",
      "ter que & 3\\\\\\hline\n",
      "haver de & 2\\\\\\hline\n",
      "continuar por & 1\\\\\\hline\n",
      "dever a & 1\\\\\\hline\n",
      "estar para & 1\\\\\\hline\n",
      "estar por & 1\\\\\\hline\n",
      "ficar de & 1\\\\\\hline\n",
      "haver a & 1\\\\\\hline\n",
      "haver que & 1\\\\\\hline\n",
      "ir de & 1\\\\\\hline\n",
      "tender a & 1\\\\\\hline\n",
      "tornar a & 1\\\\\\hline\n"
     ]
    }
   ],
   "source": [
    "dicionario = {}\n",
    "for sentid, sentence in corpus.sentences.items():\n",
    "    for t, token in enumerate(sentence.tokens):\n",
    "        if token.deprel == \"compound\" and \"MWEPOS=AUX\" in token.head_token.misc:\n",
    "            if not token.head_token.lemma + \" \" + token.lemma in dicionario:\n",
    "                dicionario[token.head_token.lemma + \" \" + token.lemma] = 0\n",
    "            dicionario[token.head_token.lemma + \" \" + token.lemma] += 1\n",
    "\n",
    "print(sum([x[1] for x in dicionario.items()]))\n",
    "print(len(dicionario))\n",
    "print(\"\\n\".join([x + \" & \" + str(y) + \"\\\\\\\\\\\\hline\" for x, y in sorted(dicionario.items(), key=lambda k: (k[0], k[1]))]))\n",
    "print(\"\")\n",
    "print(\"\\n\".join([x + \" & \" + str(y) + \"\\\\\\\\\\\\hline\" for x, y in sorted(dicionario.items(), key=lambda k: (-k[1], k[0]))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbos auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3541\n",
      "23\n",
      "acabar & 56\\\\\\hline\n",
      "andar & 4\\\\\\hline\n",
      "chegar & 19\\\\\\hline\n",
      "começar & 62\\\\\\hline\n",
      "continuar & 57\\\\\\hline\n",
      "costumar & 10\\\\\\hline\n",
      "deixar & 24\\\\\\hline\n",
      "dever & 217\\\\\\hline\n",
      "estar & 282\\\\\\hline\n",
      "faltar & 1\\\\\\hline\n",
      "ficar & 11\\\\\\hline\n",
      "haver & 37\\\\\\hline\n",
      "ir & 358\\\\\\hline\n",
      "parar & 3\\\\\\hline\n",
      "parecer & 17\\\\\\hline\n",
      "passar & 39\\\\\\hline\n",
      "poder & 394\\\\\\hline\n",
      "procurar & 1\\\\\\hline\n",
      "quer & 1\\\\\\hline\n",
      "ser & 1304\\\\\\hline\n",
      "ter & 536\\\\\\hline\n",
      "vir & 68\\\\\\hline\n",
      "voltar & 40\\\\\\hline\n",
      "\n",
      "ser & 1304\\\\\\hline\n",
      "ter & 536\\\\\\hline\n",
      "poder & 394\\\\\\hline\n",
      "ir & 358\\\\\\hline\n",
      "estar & 282\\\\\\hline\n",
      "dever & 217\\\\\\hline\n",
      "vir & 68\\\\\\hline\n",
      "começar & 62\\\\\\hline\n",
      "continuar & 57\\\\\\hline\n",
      "acabar & 56\\\\\\hline\n",
      "voltar & 40\\\\\\hline\n",
      "passar & 39\\\\\\hline\n",
      "haver & 37\\\\\\hline\n",
      "deixar & 24\\\\\\hline\n",
      "chegar & 19\\\\\\hline\n",
      "parecer & 17\\\\\\hline\n",
      "ficar & 11\\\\\\hline\n",
      "costumar & 10\\\\\\hline\n",
      "andar & 4\\\\\\hline\n",
      "parar & 3\\\\\\hline\n",
      "faltar & 1\\\\\\hline\n",
      "procurar & 1\\\\\\hline\n",
      "quer & 1\\\\\\hline\n"
     ]
    }
   ],
   "source": [
    "dicionario = {}\n",
    "for sentid, sentence in corpus.sentences.items():\n",
    "    for t, token in enumerate(sentence.tokens):\n",
    "        if token.upos == \"AUX\" and token.head_token.upos == \"VERB\":\n",
    "            if not token.lemma in dicionario:\n",
    "                dicionario[token.lemma] = 0\n",
    "            dicionario[token.lemma] += 1\n",
    "\n",
    "print(sum([x[1] for x in dicionario.items()]))\n",
    "print(len(dicionario))\n",
    "print(\"\\n\".join([x + \" & \" + str(y) + \"\\\\\\\\\\\\hline\" for x, y in sorted(dicionario.items(), key=lambda k: (k[0], k[1]))]))\n",
    "print(\"\")\n",
    "print(\"\\n\".join([x + \" & \" + str(y) + \"\\\\\\\\\\\\hline\" for x, y in sorted(dicionario.items(), key=lambda k: (-k[1], k[0]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "2\n",
      "estar & 33\\\\\\hline\n",
      "ser & 105\\\\\\hline\n",
      "\n",
      "ser & 105\\\\\\hline\n",
      "estar & 33\\\\\\hline\n"
     ]
    }
   ],
   "source": [
    "#Verbos de ligação\n",
    "\n",
    "dicionario = {}\n",
    "for sentid, sentence in corpus.sentences.items():\n",
    "    for t, token in enumerate(sentence.tokens):\n",
    "        if token.upos == \"AUX\" and token.deprel == \"cop\" and token.head_token.upos == \"VERB\":\n",
    "            if not token.lemma in dicionario:\n",
    "                dicionario[token.lemma] = 0\n",
    "            dicionario[token.lemma] += 1\n",
    "\n",
    "print(sum([x[1] for x in dicionario.items()]))\n",
    "print(len(dicionario))\n",
    "print(\"\\n\".join([x + \" & \" + str(y) + \"\\\\\\\\\\\\hline\" for x, y in sorted(dicionario.items(), key=lambda k: (k[0], k[1]))]))\n",
    "print(\"\")\n",
    "print(\"\\n\".join([x + \" & \" + str(y) + \"\\\\\\\\\\\\hline\" for x, y in sorted(dicionario.items(), key=lambda k: (-k[1], k[0]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2256\n",
      "23\n",
      "acabar & 56\\\\\\hline\n",
      "andar & 4\\\\\\hline\n",
      "chegar & 19\\\\\\hline\n",
      "começar & 62\\\\\\hline\n",
      "continuar & 57\\\\\\hline\n",
      "costumar & 10\\\\\\hline\n",
      "deixar & 24\\\\\\hline\n",
      "dever & 217\\\\\\hline\n",
      "estar & 249\\\\\\hline\n",
      "faltar & 1\\\\\\hline\n",
      "ficar & 10\\\\\\hline\n",
      "haver & 37\\\\\\hline\n",
      "ir & 358\\\\\\hline\n",
      "parar & 3\\\\\\hline\n",
      "parecer & 17\\\\\\hline\n",
      "passar & 39\\\\\\hline\n",
      "poder & 394\\\\\\hline\n",
      "procurar & 1\\\\\\hline\n",
      "quer & 1\\\\\\hline\n",
      "ser & 53\\\\\\hline\n",
      "ter & 536\\\\\\hline\n",
      "vir & 68\\\\\\hline\n",
      "voltar & 40\\\\\\hline\n",
      "\n",
      "ter & 536\\\\\\hline\n",
      "poder & 394\\\\\\hline\n",
      "ir & 358\\\\\\hline\n",
      "estar & 249\\\\\\hline\n",
      "dever & 217\\\\\\hline\n",
      "vir & 68\\\\\\hline\n",
      "começar & 62\\\\\\hline\n",
      "continuar & 57\\\\\\hline\n",
      "acabar & 56\\\\\\hline\n",
      "ser & 53\\\\\\hline\n",
      "voltar & 40\\\\\\hline\n",
      "passar & 39\\\\\\hline\n",
      "haver & 37\\\\\\hline\n",
      "deixar & 24\\\\\\hline\n",
      "chegar & 19\\\\\\hline\n",
      "parecer & 17\\\\\\hline\n",
      "costumar & 10\\\\\\hline\n",
      "ficar & 10\\\\\\hline\n",
      "andar & 4\\\\\\hline\n",
      "parar & 3\\\\\\hline\n",
      "faltar & 1\\\\\\hline\n",
      "procurar & 1\\\\\\hline\n",
      "quer & 1\\\\\\hline\n"
     ]
    }
   ],
   "source": [
    "#Verbos de voz passiva\n",
    "\n",
    "dicionario = {}\n",
    "for sentid, sentence in corpus.sentences.items():\n",
    "    for t, token in enumerate(sentence.tokens):\n",
    "        if token.upos == \"AUX\" and token.deprel == \"aux\" and token.head_token.upos == \"VERB\":\n",
    "            if not token.lemma in dicionario:\n",
    "                dicionario[token.lemma] = 0\n",
    "            dicionario[token.lemma] += 1\n",
    "\n",
    "print(sum([x[1] for x in dicionario.items()]))\n",
    "print(len(dicionario))\n",
    "print(\"\\n\".join([x + \" & \" + str(y) + \"\\\\\\\\\\\\hline\" for x, y in sorted(dicionario.items(), key=lambda k: (k[0], k[1]))]))\n",
    "print(\"\")\n",
    "print(\"\\n\".join([x + \" & \" + str(y) + \"\\\\\\\\\\\\hline\" for x, y in sorted(dicionario.items(), key=lambda k: (-k[1], k[0]))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Não é locução verbal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150\n",
      "196\n",
      "abster & 2 & querer & 108\\\\\\hline\n",
      "acabar & 3 & conseguir & 83\\\\\\hline\n",
      "aceder & 1 & tentar & 64\\\\\\hline\n",
      "aceitar & 6 & fazer & 45\\\\\\hline\n",
      "achar & 5 & pretender & 39\\\\\\hline\n",
      "aconselhar & 5 & permitir & 37\\\\\\hline\n",
      "acreditar & 2 & decidir & 33\\\\\\hline\n",
      "acusar & 30 & acusar & 30\\\\\\hline\n",
      "admitir & 12 & deixar & 27\\\\\\hline\n",
      "afirmar & 13 & procurar & 21\\\\\\hline\n",
      "aguentar & 1 & levar & 20\\\\\\hline\n",
      "ajudar & 9 & ver & 19\\\\\\hline\n",
      "alegar & 3 & dar & 18\\\\\\hline\n",
      "ambicionar & 1 & gostar & 17\\\\\\hline\n",
      "ameaçar & 14 & obrigar & 17\\\\\\hline\n",
      "andar & 2 & ser & 17\\\\\\hline\n",
      "anunciar & 2 & saber & 16\\\\\\hline\n",
      "aperceber & 1 & ameaçar & 14\\\\\\hline\n",
      "apetecer & 1 & precisar & 14\\\\\\hline\n",
      "aplicar & 1 & preferir & 14\\\\\\hline\n",
      "apostar & 1 & resolver & 14\\\\\\hline\n",
      "aprender & 5 & afirmar & 13\\\\\\hline\n",
      "apresentar & 2 & admitir & 12\\\\\\hline\n",
      "apressar & 1 & considerar & 12\\\\\\hline\n",
      "aprestar & 1 & encontrar & 12\\\\\\hline\n",
      "aproveitar & 1 & ter & 12\\\\\\hline\n",
      "arriscar & 2 & dizer & 11\\\\\\hline\n",
      "atender & 1 & destinar & 10\\\\\\hline\n",
      "atrever & 1 & limitar & 10\\\\\\hline\n",
      "autorizar & 3 & ajudar & 9\\\\\\hline\n",
      "avisar & 1 & ficar & 9\\\\\\hline\n",
      "bastar & 3 & preparar & 9\\\\\\hline\n",
      "caber & 1 & esperar & 8\\\\\\hline\n",
      "cansar & 1 & pensar & 8\\\\\\hline\n",
      "cessar & 1 & comprometer & 7\\\\\\hline\n",
      "chamar & 4 & consistir & 7\\\\\\hline\n",
      "citar & 1 & continuar & 7\\\\\\hline\n",
      "começar & 1 & convidar & 7\\\\\\hline\n",
      "comprometer & 7 & recusar & 7\\\\\\hline\n",
      "concordar & 3 & aceitar & 6\\\\\\hline\n",
      "condenar & 1 & convencer & 6\\\\\\hline\n",
      "conduzir & 1 & estar & 6\\\\\\hline\n",
      "confidenciar & 1 & manter & 6\\\\\\hline\n",
      "confirmar & 1 & prometer & 6\\\\\\hline\n",
      "conseguir & 83 & achar & 5\\\\\\hline\n",
      "considerar & 12 & aconselhar & 5\\\\\\hline\n",
      "consistir & 7 & aprender & 5\\\\\\hline\n",
      "consultar & 1 & forçar & 5\\\\\\hline\n",
      "contar & 1 & mandar & 5\\\\\\hline\n",
      "continuar & 7 & parecer & 5\\\\\\hline\n",
      "contribuir & 3 & passar & 5\\\\\\hline\n",
      "convencer & 6 & propor & 5\\\\\\hline\n",
      "convencionar & 1 & tender & 5\\\\\\hline\n",
      "convidar & 7 & visar & 5\\\\\\hline\n",
      "credenciar & 1 & chamar & 4\\\\\\hline\n",
      "criticar & 1 & desejar & 4\\\\\\hline\n",
      "culpar & 1 & encarregar & 4\\\\\\hline\n",
      "dar & 18 & evitar & 4\\\\\\hline\n",
      "decidir & 33 & impedir & 4\\\\\\hline\n",
      "declarar & 3 & interessar & 4\\\\\\hline\n",
      "declinar & 1 & proibir & 4\\\\\\hline\n",
      "dedicar & 2 & reconhecer & 4\\\\\\hline\n",
      "deixar & 27 & sentir & 4\\\\\\hline\n",
      "depender & 1 & tencionar & 4\\\\\\hline\n",
      "desafiar & 2 & tratar & 4\\\\\\hline\n",
      "desejar & 4 & acabar & 3\\\\\\hline\n",
      "desistir & 1 & alegar & 3\\\\\\hline\n",
      "destinar & 10 & autorizar & 3\\\\\\hline\n",
      "dever & 3 & bastar & 3\\\\\\hline\n",
      "dispor & 3 & concordar & 3\\\\\\hline\n",
      "dizer & 11 & contribuir & 3\\\\\\hline\n",
      "duvidar & 1 & declarar & 3\\\\\\hline\n",
      "empenhar & 2 & dever & 3\\\\\\hline\n",
      "encarregar & 4 & dispor & 3\\\\\\hline\n",
      "encontrar & 12 & insistir & 3\\\\\\hline\n",
      "ensinar & 1 & ir & 3\\\\\\hline\n",
      "equivaler & 1 & optar & 3\\\\\\hline\n",
      "escolher & 1 & ousar & 3\\\\\\hline\n",
      "escusar & 2 & pôr & 3\\\\\\hline\n",
      "esperar & 8 & vir & 3\\\\\\hline\n",
      "estar & 6 & abster & 2\\\\\\hline\n",
      "estimar & 1 & acreditar & 2\\\\\\hline\n",
      "estimular & 1 & andar & 2\\\\\\hline\n",
      "estudar & 1 & anunciar & 2\\\\\\hline\n",
      "evitar & 4 & apresentar & 2\\\\\\hline\n",
      "exigir & 1 & arriscar & 2\\\\\\hline\n",
      "exortar & 1 & dedicar & 2\\\\\\hline\n",
      "experimentar & 1 & desafiar & 2\\\\\\hline\n",
      "falar & 2 & empenhar & 2\\\\\\hline\n",
      "fartar & 1 & escusar & 2\\\\\\hline\n",
      "fazer & 45 & falar & 2\\\\\\hline\n",
      "ficar & 9 & garantir & 2\\\\\\hline\n",
      "fingir & 1 & haver & 2\\\\\\hline\n",
      "foi & 1 & imaginar & 2\\\\\\hline\n",
      "forçar & 5 & impor & 2\\\\\\hline\n",
      "garantir & 2 & importar & 2\\\\\\hline\n",
      "gostar & 17 & incentivar & 2\\\\\\hline\n",
      "habituar & 1 & mostrar & 2\\\\\\hline\n",
      "haver & 2 & necessitar & 2\\\\\\hline\n",
      "imaginar & 2 & negar & 2\\\\\\hline\n",
      "impedir & 4 & ouvir & 2\\\\\\hline\n",
      "impor & 2 & parar & 2\\\\\\hline\n",
      "importar & 2 & queixar & 2\\\\\\hline\n",
      "incentivar & 2 & receber & 2\\\\\\hline\n",
      "incluir & 1 & referir & 2\\\\\\hline\n",
      "indagar & 1 & resistir & 2\\\\\\hline\n",
      "influenciar & 1 & sentar & 2\\\\\\hline\n",
      "informar & 1 & tornar & 2\\\\\\hline\n",
      "insinuar & 1 & aceder & 1\\\\\\hline\n",
      "insistir & 3 & aguentar & 1\\\\\\hline\n",
      "instar & 1 & ambicionar & 1\\\\\\hline\n",
      "interessar & 4 & aperceber & 1\\\\\\hline\n",
      "ir & 3 & apetecer & 1\\\\\\hline\n",
      "lembrar & 1 & aplicar & 1\\\\\\hline\n",
      "levar & 20 & apostar & 1\\\\\\hline\n",
      "limitar & 10 & apressar & 1\\\\\\hline\n",
      "mandar & 5 & aprestar & 1\\\\\\hline\n",
      "manter & 6 & aproveitar & 1\\\\\\hline\n",
      "merecer & 1 & atender & 1\\\\\\hline\n",
      "mostrar & 2 & atrever & 1\\\\\\hline\n",
      "necessitar & 2 & avisar & 1\\\\\\hline\n",
      "negar & 2 & caber & 1\\\\\\hline\n",
      "obrigar & 17 & cansar & 1\\\\\\hline\n",
      "optar & 3 & cessar & 1\\\\\\hline\n",
      "orgulhar & 1 & citar & 1\\\\\\hline\n",
      "ousar & 3 & começar & 1\\\\\\hline\n",
      "ouvir & 2 & condenar & 1\\\\\\hline\n",
      "parar & 2 & conduzir & 1\\\\\\hline\n",
      "parecer & 5 & confidenciar & 1\\\\\\hline\n",
      "passado & 1 & confirmar & 1\\\\\\hline\n",
      "passar & 5 & consultar & 1\\\\\\hline\n",
      "pedir & 1 & contar & 1\\\\\\hline\n",
      "pensar & 8 & convencionar & 1\\\\\\hline\n",
      "perder & 1 & credenciar & 1\\\\\\hline\n",
      "permanecer & 1 & criticar & 1\\\\\\hline\n",
      "permitir & 37 & culpar & 1\\\\\\hline\n",
      "persuadir & 1 & declinar & 1\\\\\\hline\n",
      "planear & 1 & depender & 1\\\\\\hline\n",
      "poder & 1 & desistir & 1\\\\\\hline\n",
      "precisar & 14 & duvidar & 1\\\\\\hline\n",
      "preferir & 14 & ensinar & 1\\\\\\hline\n",
      "preparar & 9 & equivaler & 1\\\\\\hline\n",
      "pretender & 39 & escolher & 1\\\\\\hline\n",
      "prevenir & 1 & estimar & 1\\\\\\hline\n",
      "prever & 1 & estimular & 1\\\\\\hline\n",
      "procurar & 21 & estudar & 1\\\\\\hline\n",
      "proibir & 4 & exigir & 1\\\\\\hline\n",
      "projectar & 1 & exortar & 1\\\\\\hline\n",
      "prometer & 6 & experimentar & 1\\\\\\hline\n",
      "propiciar & 1 & fartar & 1\\\\\\hline\n",
      "propor & 5 & fingir & 1\\\\\\hline\n",
      "provocar & 1 & foi & 1\\\\\\hline\n",
      "pôr & 3 & habituar & 1\\\\\\hline\n",
      "queixar & 2 & incluir & 1\\\\\\hline\n",
      "querer & 108 & indagar & 1\\\\\\hline\n",
      "receber & 2 & influenciar & 1\\\\\\hline\n",
      "reclamar & 1 & informar & 1\\\\\\hline\n",
      "recomeçar & 1 & insinuar & 1\\\\\\hline\n",
      "recompensar & 1 & instar & 1\\\\\\hline\n",
      "reconhecer & 4 & lembrar & 1\\\\\\hline\n",
      "recordar & 1 & merecer & 1\\\\\\hline\n",
      "recusar & 7 & orgulhar & 1\\\\\\hline\n",
      "reduzir & 1 & passado & 1\\\\\\hline\n",
      "referir & 2 & pedir & 1\\\\\\hline\n",
      "resistir & 2 & perder & 1\\\\\\hline\n",
      "resolver & 14 & permanecer & 1\\\\\\hline\n",
      "respeitar & 1 & persuadir & 1\\\\\\hline\n",
      "restar & 1 & planear & 1\\\\\\hline\n",
      "retirar & 1 & poder & 1\\\\\\hline\n",
      "saber & 16 & prevenir & 1\\\\\\hline\n",
      "salientar & 1 & prever & 1\\\\\\hline\n",
      "sentar & 2 & projectar & 1\\\\\\hline\n",
      "sentir & 4 & propiciar & 1\\\\\\hline\n",
      "ser & 17 & provocar & 1\\\\\\hline\n",
      "soar & 1 & reclamar & 1\\\\\\hline\n",
      "sonhar & 1 & recomeçar & 1\\\\\\hline\n",
      "sublinhar & 1 & recompensar & 1\\\\\\hline\n",
      "sujeitar & 1 & recordar & 1\\\\\\hline\n",
      "suportar & 1 & reduzir & 1\\\\\\hline\n",
      "surgir & 1 & respeitar & 1\\\\\\hline\n",
      "suspeitar & 1 & restar & 1\\\\\\hline\n",
      "tardar & 1 & retirar & 1\\\\\\hline\n",
      "teimar & 1 & salientar & 1\\\\\\hline\n",
      "temer & 1 & soar & 1\\\\\\hline\n",
      "tencionar & 4 & sonhar & 1\\\\\\hline\n",
      "tender & 5 & sublinhar & 1\\\\\\hline\n",
      "tentar & 64 & sujeitar & 1\\\\\\hline\n",
      "ter & 12 & suportar & 1\\\\\\hline\n",
      "tornar & 2 & surgir & 1\\\\\\hline\n",
      "tratar & 4 & suspeitar & 1\\\\\\hline\n",
      "trazer & 1 & tardar & 1\\\\\\hline\n",
      "ver & 19 & teimar & 1\\\\\\hline\n",
      "vir & 3 & temer & 1\\\\\\hline\n",
      "virar & 1 & trazer & 1\\\\\\hline\n",
      "visar & 5 & virar & 1\\\\\\hline\n",
      "voltar & 1 & voltar & 1\\\\\\hline\n"
     ]
    }
   ],
   "source": [
    "dicionario = {}\n",
    "for sentid, sentence in corpus.sentences.items():\n",
    "    for t, token in enumerate(sentence.tokens):\n",
    "        if token.upos == \"VERB\" and token.head_token.upos == \"VERB\" and token.deprel == \"xcomp\":\n",
    "            if not token.head_token.lemma in dicionario:\n",
    "                dicionario[token.head_token.lemma] = 0\n",
    "            dicionario[token.head_token.lemma] += 1\n",
    "\n",
    "print(sum([x[1] for x in dicionario.items()]))\n",
    "print(len(dicionario))\n",
    "\n",
    "sorted_alph = sorted(dicionario.items(), key=lambda k: (k[0], k[1]))\n",
    "sorted_freq = sorted(dicionario.items(), key=lambda k: (-k[1], k[0]))\n",
    "for i in range(len(dicionario.items())):\n",
    "    print(sorted_alph[i][0] + \" & \" + str(sorted_alph[i][1]) + \" & \" + sorted_freq[i][0] + \" & \" + str(sorted_freq[i][1]) + \"\\\\\\\\\\\\hline\")\n",
    "\n",
    "#print(\"\\n\".join([x + \" & \" + str(y) + \"\\\\\\\\\\\\hline\" for x, y in sorted(dicionario.items(), key=lambda k: (k[0], k[1]))]))\n",
    "#print(\"\")\n",
    "#print(\"\\n\".join([x + \" & \" + str(y) + \"\\\\\\\\\\\\hline\" for x, y in sorted(dicionario.items(), key=lambda k: (-k[1], k[0]))]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
